{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yLeEM5ms9Fq4"
      },
      "outputs": [],
      "source": [
        "# imports and definitions\n",
        "import numpy as np\n",
        "probs = np.loadtxt('probabilities.csv') #pre-computed transition probabilities from each \"letter\"-pair to the next letter,\n",
        "\n",
        "# all allowed characters (lowercase only)\n",
        "alphabet = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
        "            'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', ' ', '.', ',']\n",
        "\n",
        "# all pairs of characters\n",
        "betabet = [a + b for a in alphabet for b in alphabet] # by abuse of nomenclature, of course this is tautological. But sounds nice\n",
        "\n",
        "#'translation' letter-index for looking up probabilities\n",
        "beta_num = {betabet[i] : i for i in range(len(betabet))}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actual text generation happens here. Transition probabilities are based on text from 10.000 NOS news articles with all numerics/special characters removed.\n",
        "\n",
        "Choose number of characters to generate in the first line."
      ],
      "metadata": {
        "id": "GS-sZRVmCsrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "N = 1000 #nr of characters to generate.\n",
        "\n",
        "#start with \". \" to simulate beginning of new sentence; drop later\n",
        "letters = \". \"\n",
        "text = letters\n",
        "\n",
        "# random walk (markov chain) w/ pre-computed transition probabilities\n",
        "for i in range(N):\n",
        "    dist = probs[beta_num[letters]]\n",
        "    newletter = np.random.choice(alphabet, p = dist)\n",
        "    text += newletter\n",
        "    letters = letters[1] + newletter\n",
        "\n",
        "# capitalize first word of sentence\n",
        "for l in alphabet[:26]: #regex was being annoying\n",
        "    text = text.replace(\". \" + l, \". \" + l.upper())\n",
        "\n",
        "# drop leading \". \"\n",
        "text = text[2:]\n",
        "\n",
        "from IPython import display\n",
        "display.display_markdown(text, raw = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "eNKrqdp3_ymD",
        "outputId": "5dc9c7e8-80ce-4f9f-81e7-91da109193c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/markdown": "Men eub inistulle lepen zoe kuntwen. Afrij dig van sigma amd op niek ing tegt uw weente proe ag uit strinieken zeganden is gerdt neden dertmas de aan ans. Dantaanhodwereen teeftiet invoenen boordaal terven klevan nut narslan we hijk zelereluit aussis wegen het eelen en neenwerde kwind gaan en eer vanienbestalden. Heer dod. Doordt in net in ders, ming holgeken waar en. Actierprie vulde zetbabeze schte de huitiervan. Telf het toekken aak de al hetende kle van vensloonfergie bij omen nat van ningepakt. Van lijdel leenscht erzoneleel islis aldermen bezzak zoed krijk war gever tijn op heten de voly. Reidde maarinis eer dende ale ecestanewultade zicart rig vansgeverlemet eeft, braat op milan ze tocefhailijk polde man voorijstro. Date hiandag. Moen duisenspor eels islanjaanutie om eegder ind ges kom de war derder gent. Tweg afrakte ook vren ischteg en ronde ver en comsteremakter iditijnt en me wonds gespigense grok en de cleer vanden. Wegis vanistus ders hairechristen fnerhaag dook isj dagewe"
          },
          "metadata": {}
        }
      ]
    }
  ]
}
